{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OpenAI Python basics\n",
    "\n",
    "your .env file will need this\n",
    "\n",
    "```\n",
    "OPENAI_API_KEY=\"YOUR KEY\"\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -q openai==1.14.3\n",
    "import os, json\n",
    "from openai import OpenAI\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OpenAI libraries like for either the environment variable or the openai.api_key to be set\n",
    "load_dotenv(\".env\", override=True)\n",
    "\n",
    "## openai will look through environment variables itself to find the the OPENAI_API_KEY \n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "models_list = client.models.list().dict()\n",
    "\n",
    "# Convert the dictionary to a pretty-printed JSON string\n",
    "pretty_json = json.dumps(models_list, indent=4)\n",
    "\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=[\n",
    "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\": \"user\", \"content\": \"What color is the sky?\"}\n",
    "  ]\n",
    ")\n",
    "\n",
    "pretty_json = json.dumps(completion.dict(), indent=4)\n",
    "print(pretty_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_context = \"The color of the sky is purple today\"\n",
    "\n",
    "\n",
    "system_prompt = f\"\"\"\n",
    "You are a helpful AI assistant that answers questions using the provided context.\n",
    "If you can't answer the question using the provided context, say \"I don't know\".\n",
    "Don't apologize, and don't say you are an AI assistant.\n",
    "\n",
    "Context: {retrieved_context}\n",
    "\"\"\"\n",
    "\n",
    "question = \"What is the sky like today?\"\n",
    "\n",
    "messages = [\n",
    "    {\"role\":\"system\", \"content\": system_prompt},\n",
    "    {\"role\":\"user\", \"content\": question}\n",
    "]\n",
    "\n",
    "\n",
    "completion = client.chat.completions.create(\n",
    "  model=\"gpt-3.5-turbo\",\n",
    "  messages=messages\n",
    ")\n",
    "\n",
    "\n",
    "print(completion.choices[0].message.content)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
